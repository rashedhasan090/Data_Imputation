Machine learning is a data driven discipline which requires processing a high amount of data. Data set considered as high quality should have enough size, important features and be consistent. One of the challenges for most real-world applications of Machine Learning is that there is always missing data in most of the datasets. A common strategy to tackle this issue is data Imputation. Imputation retains the majority of the data and information in a dataset by substituting missing data with another value. A prior research work has explored multivariate imputation with four widely used Machine Learning models, i.e. Bayesian Ridge, K-Nearest Neighbor Regression, Random Forests Regression, Artificial Neural Network Regression, on sparse datasets, and compare each of their performance in terms of certain standardized metrics. Our observation is that, throughout their research, they failed to explore the potential opportunity to improve the imputation algorithm by utilizing the co-relations between different features and imputation strategy. Our goal is to implement the imputation with different strategies, including mean, median, most frequent, and etc. and incorporate the correlation information among features, and evaluate the results by comparing to the previous work.
